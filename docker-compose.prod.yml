services:
  opensearch:
    image: opensearchproject/opensearch:2
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data

  server:
    build:
      context: .
      dockerfile: server/Dockerfile
    depends_on:
      - opensearch
    env_file:
      - ./server/.env
    environment:
      CHUNKSMITH_ENV: prod
      CHUNKSMITH_STORAGE_DIR: /app/storage

      # In prod we proxy /api via nginx, so CORS is usually not needed.
      # Keep it permissive for local smoke tests.
      CHUNKSMITH_CORS_ORIGINS: http://localhost:8080

      OPENSEARCH_HOST: http://opensearch:9200
      OPENSEARCH_VERIFY_SSL: "false"

      # OpenAI-compatible endpoint: loaded from ./server/.env via env_file
      # These lines only provide fallback if .env is missing the variable
      # OPENAI_BASE_URL: (from env_file)
      # OPENAI_API_KEY: (from env_file)
      # EMBEDDING_MODELS: (from env_file)
    volumes:
      - ./server/storage:/app/storage
    # Expose internally; frontend talks to it via nginx
    expose:
      - "8000"
    command:
      [
        "uvicorn",
        "app.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8000",
        "--workers",
        "4",
      ]
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile.prod
    depends_on:
      - server
    ports:
      - "8080:80"
    restart: unless-stopped

volumes:
  opensearch-data:
