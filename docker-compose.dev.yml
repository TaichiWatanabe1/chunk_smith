services:
  opensearch:
    image: opensearchproject/opensearch:2
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data

    restart: unless-stopped

  server:
    build:
      context: .
      dockerfile: server/Dockerfile
    depends_on:
      - opensearch
    environment:
      CHUNKSMITH_ENV: dev
      CHUNKSMITH_STORAGE_DIR: /app/storage
      # Vite dev server in this repo runs on 3000
      CHUNKSMITH_CORS_ORIGINS: http://localhost:3000

      OPENSEARCH_HOST: http://opensearch:9200
      OPENSEARCH_VERIFY_SSL: "false"

      # OpenAI-compatible endpoint (set via environment or .env)
      # For a local server running on the host (Docker Desktop):
      #   OPENAI_BASE_URL=http://host.docker.internal:8080/v1
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      EMBEDDING_MODELS: text-embedding-3-large,text-embedding-3-small
    ports:
      - "8000:8000"
    volumes:
      - ./server/app:/app/app
      - ./server/storage:/app/storage
      # Optional: mount a local env file (create from server/.env.example)
      # - ./server/.env:/app/.env:ro
    command:
      [
        "uvicorn",
        "app.main:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8000",
        "--reload",
      ]

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    depends_on:
      - server
    environment:
      # Browser should reach API via host-mapped port
      VITE_API_BASE: http://localhost:8000
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: ["npm", "run", "dev", "--", "--host", "0.0.0.0", "--port", "3000"]

  # Optional: run an OpenAI-compatible server separately (host or another container)

volumes:
  opensearch-data:
